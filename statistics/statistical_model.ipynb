{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 10000.0\n",
      "Mean Squared Error (MSE): 100000000.0\n",
      "Root Mean Squared Error (RMSE): 10000.0\n",
      "R-Squared (R2): 0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Actual and Predicted Values\n",
    "y_actual = np.array([200000, 150000, 300000, 250000, 400000])\n",
    "y_predicted = np.array([210000, 160000, 310000, 240000, 390000])\n",
    "\n",
    "# Calculate Metrics\n",
    "mae = mean_absolute_error(y_actual, y_predicted)\n",
    "mse = mean_squared_error(y_actual, y_predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_actual, y_predicted)\n",
    "\n",
    "# Display Results\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-Squared (R2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[45  5]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.8\n",
      "F1 Score: 0.8421052631578947\n",
      "ROC-AUC Score: 0.8500000000000001\n",
      "Logarithmic Loss: 5.406548008367573\n",
      "Specificity: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, log_loss\n",
    "\n",
    "# Actual and Predicted Values\n",
    "y_true = [1]*50 + [0]*50  # 50 actual positives, 50 actual negatives\n",
    "y_pred = [1]*40 + [0]*10 + [1]*5 + [0]*45  # Model predictions\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "logarithim_loss = log_loss(y_true, y_pred)\n",
    "specificity = conf_matrix[0,0] / (conf_matrix[0,0] + conf_matrix[0,1])\n",
    "\n",
    "# Display Results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "print(\"Logarithmic Loss:\", logarithim_loss)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.8756469540734731\n",
      "Adjusted Rand Index (ARI): 1.0\n",
      "Normalized Mutual Information (NMI): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate sample data\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=42)\n",
    "\n",
    "# Fit K-Means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "# Internal Metrics\n",
    "silhouette = silhouette_score(X, y_pred)\n",
    "print(\"Silhouette Score:\", silhouette)\n",
    "\n",
    "# External Metrics (using true labels)\n",
    "ari = adjusted_rand_score(y_true, y_pred)\n",
    "nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "print(\"Adjusted Rand Index (ARI):\", ari)\n",
    "print(\"Normalized Mutual Information (NMI):\", nmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
